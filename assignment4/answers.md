# Контрольные вопросы к Assignment 4

---

## 1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?

Вычисления только на CPU выполняются последовательно или с ограниченным уровнем параллелизма и хорошо подходят для задач с сложной логикой и частыми ветвлениями.  
Вычисления только на GPU ориентированы на массово-параллельную обработку данных и эффективны для однотипных операций над большими массивами.

**Гибридные вычисления** сочетают использование CPU и GPU, распределяя нагрузку между ними. Это позволяет учитывать сильные стороны каждого устройства и повышать общую производительность программы.

---

## 2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?

Распределение вычислений между CPU и GPU целесообразно для задач, в которых:
- часть алгоритма плохо параллелится и лучше выполняется на CPU;
- другая часть состоит из однотипных операций над большими объёмами данных и подходит для GPU;
- требуется обработка данных, не полностью помещающихся в память GPU;
- возможно параллельное выполнение CPU- и GPU-частей.

---

## 3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?

При **синхронной передаче данных** выполнение программы блокируется до завершения копирования данных между CPU и GPU.  
При **асинхронной передаче данных** копирование выполняется параллельно с вычислениями, не блокируя основной поток выполнения.

---

## 4. Почему асинхронная передача данных может повысить производительность программы?

Асинхронная передача данных позволяет перекрывать вычисления и операции копирования.  
В то время как GPU выполняет вычисления, CPU может подготавливать новые данные или выполнять другие задачи, что снижает простои устройств и повышает общую эффективность программы.

---

## 5. Какие основные функции MPI используются для распределения и сбора данных между процессами?

К основным функциям MPI относятся:
- `MPI_Init` — инициализация MPI-среды;
- `MPI_Comm_rank` — получение номера процесса;
- `MPI_Comm_size` — получение общего числа процессов;
- `MPI_Scatter` — распределение данных между процессами;
- `MPI_Gather` — сбор данных от процессов;
- `MPI_Reduce` — редукция данных (например, сумма);
- `MPI_Barrier` — синхронизация процессов;
- `MPI_Finalize` — завершение работы с MPI.

---

## 6. Как количество процессов MPI влияет на время выполнения программы и почему?

При увеличении числа MPI-процессов вычислительная нагрузка распределяется между ними, что может уменьшить время выполнения программы.  
Однако после определённого момента рост числа процессов приводит к увеличению накладных расходов на коммуникацию и синхронизацию, из-за чего ускорение уменьшается или полностью исчезает.

---

## 7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?

Основными факторами, ограничивающими масштабируемость, являются:
- накладные расходы на обмен данными между процессами;
- задержки и пропускная способность сети;
- неравномерное распределение нагрузки;
- последовательные участки алгоритма (закон Амдала);
- ограниченные аппаратные ресурсы.

---

## 8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?

Распределённые вычисления оправданы, когда:
- объём данных или вычислений слишком велик для одного узла;
- задача хорошо параллелится;
- требуется высокая производительность и масштабируемость.

Использование распределённых вычислений неэффективно, если:
- объём данных мал;
- алгоритм содержит много последовательных операций;
- накладные расходы на коммуникацию превышают выигрыш от параллелизма.
