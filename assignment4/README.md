# Assignment 4  
## Гибридные и распределённые параллельные вычисления

Данный репозиторий содержит выполнение **Assignment 4** по теме  
**гибридных и распределённых параллельных вычислений**.

Все задания реализованы на языке **C++** с использованием **CUDA** и **MPI**  
и оформлены в виде отдельных Jupyter Notebook файлов (`.ipynb`).

---

## Структура проекта

├── task1/

│ ├── task1.ipynb # CUDA: сумма элементов массива

│ └── block_scheme.png # Блок-схема алгоритма

│

├── task2/

│ ├── task2.ipynb # CUDA: префиксная сумма (scan)

│ └── block_scheme.png # Блок-схема алгоритма

│

├── task3/

│ ├── task3.ipynb # Гибридная CPU + GPU реализация

│ └── block_scheme.png # Блок-схема гибридного процесса

│

├── task4/

│ ├── task4.ipynb # MPI: распределённая обработка массива

│ └── block_scheme.png # Блок-схема MPI-программы

│

├── answers.md # Ответы на контрольные вопросы

└── README.md


---

## Используемые технологии

- **C++**
- **CUDA**
- **MPI (Open MPI)**
- **Google Colab (GPU runtime)**
- **NVIDIA Tesla T4**

---

## Задание 1 — CUDA: сумма элементов массива

**Описание:**  
Реализовано вычисление суммы элементов массива размером `100 000` с использованием CUDA и глобальной памяти.  
Проведено сравнение с последовательной CPU-реализацией.

**Результаты:**

CPU sum: 100000

GPU sum: 100000

CPU time (ms): ~2.5

GPU time (ms): ~0.5


**Вывод:**  
GPU-реализация демонстрирует значительное ускорение по сравнению с CPU за счёт параллельного выполнения.

---

## Задание 2 — CUDA: префиксная сумма (Scan)

**Описание:**  
Реализован алгоритм префиксной суммы для массива размером `1 000 000`  
с использованием разделяемой памяти CUDA.

**Результаты:**

CPU time (ms): ~8.5

GPU time (ms): ~0.3

![Task2](task2/output2.png)


**Вывод:**  
Использование shared memory позволило существенно сократить время выполнения.

---

## Задание 3 — Гибридные вычисления (CPU + GPU)

**Описание:**  
Массив данных разделён на две части:
- первая часть обрабатывается на CPU
- вторая часть обрабатывается на GPU

Проведено сравнение CPU-, GPU- и гибридной реализаций.

**Результаты:**

CPU time (ms): ~90.7

GPU time (ms): ~3.5

Hybrid time (ms): ~74.8



**Вывод:**  
Гибридный подход позволяет сократить время выполнения по сравнению с CPU,  
однако уступает чисто GPU-реализации из-за накладных расходов на передачу данных.

---

## Задание 4 — MPI: распределённые вычисления

**Описание:**  
Реализована распределённая программа с использованием MPI.  
Массив данных разделяется между процессами, локальные результаты собираются с помощью `MPI_Reduce`.

**Результаты:**

2 процесса → ~68.9 ms

4 процесса → ~43.7 ms

8 процессов → ~33.7 ms


**Вывод:**  
При увеличении числа процессов наблюдается уменьшение времени выполнения,  
что подтверждает масштабируемость распределённой программы.  
Эксперименты выполнялись в среде Google Colab с использованием опции `--oversubscribe`.

---

## Контрольные вопросы

Ответы на контрольные вопросы представлены в файле:

answers.md


---

## Запуск

Все `.ipynb` файлы предназначены для запуска в **Google Colab**  
с включённым режимом **GPU**.

Для MPI используется команда:

```bash
mpirun --allow-run-as-root --oversubscribe -np 4 ./task4_mpi
