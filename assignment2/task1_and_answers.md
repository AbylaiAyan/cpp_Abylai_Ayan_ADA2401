# Assignment 2 - Task 1: Введение в гетерогенную параллелизацию

### **Что такое гетерогенная параллелизация?**

Гетерогенная параллелизация – это использование различных типов вычислительных устройств (CPU, GPU, FPGA и др.) для выполнения задач с максимальной эффективностью.  
Основная идея – разделять работу между устройствами в зависимости от их архитектуры и производительности для конкретного типа вычислений.

---

### **Различия между CPU и GPU**

| Параметр           | CPU                             | GPU                             |
|-------------------|---------------------------------|--------------------------------|
| Архитектура       | Несколько мощных ядер           | Тысячи простых потоков         |
| Подход к задачам  | Оптимален для последовательных и ветвящихся алгоритмов | Оптимален для массивных параллельных вычислений |
| Кэш и память      | Большой кэш, сложная иерархия  | Меньший кэш, высокая пропускная способность глобальной памяти |

---

### **Преимущества гетерогенной параллелизации**

- Более эффективное использование ресурсов системы  
- Ускорение вычислений за счёт параллельной обработки  
- Возможность обработки больших массивов данных, которые неэффективно вычислять только на CPU  
- Гибкость в выборе устройства для конкретной задачи

---

### **Примеры реальных приложений**

- Машинное обучение: тренировка нейросетей на GPU, предобработка данных на CPU  
- Компьютерная графика: рендеринг сцен с использованием CPU и GPU  
- Научные расчёты: моделирование физики, молекулярная динамика  
- Финансовые расчёты: анализ больших потоков данных и рисков

---

# Контрольные вопросы к Assignment 2  
## OpenMP, CUDA и гетерогенные вычисления

---

### 1. Что понимается под гетерогенной параллелизацией?
Гетерогенная параллелизация — это подход, при котором в одной программе используются разные вычислительные устройства, чаще всего центральный процессор (CPU) и графический процессор (GPU).  
Идея заключается в распределении работы между ними: CPU выполняет управляющую логику и последовательные части программы, а GPU — вычислительно тяжёлые и хорошо параллелящиеся фрагменты. Такой подход позволяет ускорить выполнение задач и эффективнее использовать возможности аппаратуры.

---

### 2. В чём принципиальные различия архитектур CPU и GPU?
CPU состоит из небольшого количества мощных универсальных ядер. Он оптимизирован для выполнения сложных инструкций, работы с ветвлениями, рекурсией и последовательными алгоритмами. У CPU развита система кэшей и логика управления.  

GPU, в свою очередь, содержит сотни или тысячи более простых ядер. Он рассчитан на одновременное выполнение большого числа однотипных операций над разными данными. Благодаря этому GPU обеспечивает высокую производительность в задачах с массовым параллелизмом, но хуже справляется с задачами со сложной логикой.

---

### 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?
GPU лучше всего подходит для задач, где можно выполнять одинаковые операции над большими массивами данных параллельно. К таким задачам относятся умножение матриц, обработка изображений и видео, моделирование физических процессов, обучение нейронных сетей.  

CPU лучше использовать для задач, где важна последовательность выполнения, присутствует большое количество условий, ветвлений и зависимостей между шагами. Это может быть управляющая логика программы, обработка ввода-вывода и сложные алгоритмы с нерегулярной структурой.

---

### 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?
OpenMP эффективно работает, когда алгоритм можно легко разделить на независимые части. Однако многие алгоритмы содержат зависимости между итерациями, требуют частой синхронизации потоков или имеют неравномерную нагрузку. В таких случаях параллельное выполнение либо невозможно, либо накладные расходы на создание и синхронизацию потоков сводят на нет выигрыш от распараллеливания.

---

### 5. В чём заключается основная идея алгоритма сортировки слиянием?
Сортировка слиянием основана на принципе «разделяй и властвуй». Исходный массив разбивается на более мелкие части, каждая из которых сортируется отдельно. После этого отсортированные подмассивы последовательно сливаются в один общий отсортированный массив. Такой подход обеспечивает хорошую асимптотику и стабильность сортировки.

---

### 6. Какие сложности возникают при реализации сортировки слиянием на GPU?
Основная сложность заключается в том, что сортировка слиянием является рекурсивным алгоритмом, а GPU плохо подходит для рекурсии. Кроме того, операция слияния не так просто эффективно распараллеливается. Дополнительные трудности связаны с синхронизацией потоков и эффективным использованием памяти GPU, что может снижать производительность.

---

### 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?
Размер блока и сетки определяет, сколько потоков одновременно выполняется на GPU и как они распределяются по вычислительным блокам. Если блоки слишком маленькие, ресурсы GPU используются не полностью. Если слишком большие — может не хватать регистров или разделяемой памяти. Правильный выбор параметров позволяет максимально загрузить GPU и скрывать задержки доступа к памяти.

---

### 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?
CPU и GPU имеют разные сильные стороны. Используя их совместно, можно поручить каждому устройству ту часть работы, для которой оно подходит лучше всего. Это позволяет сократить общее время выполнения программы и более эффективно использовать вычислительные ресурсы.

