{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "id": "z5igOJt8yVry",
        "outputId": "20c68586-4fc6-49f9-b6f8-a8114f579ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvcc: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "D78axwbtyeW6",
        "outputId": "c6fea757-38e5-4416-8a3c-48da44efd992",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 28 16:29:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка CUDA 12.1 (пример)\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/12.1.105/local_installers/cuda_12.1.105_535.54.03_linux.run\n",
        "!chmod +x cuda_12.1.105_535.54.03_linux.run\n",
        "!./cuda_12.1.105_535.54.03_linux.run --silent --toolkit\n",
        "\n",
        "# Добавляем в PATH\n",
        "import os\n",
        "os.environ['PATH'] += ':/usr/local/cuda-12.1/bin'\n"
      ],
      "metadata": {
        "id": "6ZKbAYwdyuWZ",
        "outputId": "b2d9253e-7e97-4b59-cf84-58c81e6b98f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-28 16:29:16--  https://developer.download.nvidia.com/compute/cuda/12.1.105/local_installers/cuda_12.1.105_535.54.03_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.32.152.107, 23.32.152.105, 23.32.152.106, ...\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.32.152.107|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-12-28 16:29:16 ERROR 404: Not Found.\n",
            "\n",
            "chmod: cannot access 'cuda_12.1.105_535.54.03_linux.run': No such file or directory\n",
            "/bin/bash: line 1: ./cuda_12.1.105_535.54.03_linux.run: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n"
      ],
      "metadata": {
        "id": "Ffg4ktZ4yypg",
        "outputId": "99cd1925-27a9-445e-cc4d-b4761ac456c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lab4_cuda_merge.cu\n",
        "// lab4_cuda_merge.cpp\n",
        "// Параллельная сортировка слиянием на GPU с использованием CUDA\n",
        "//\n",
        "// Программа:\n",
        "// 1) Создаёт массивы размером 10 000 и 100 000 элементов\n",
        "// 2) Разделяет массив на подмассивы, каждый из которых сортирует отдельный блок\n",
        "// 3) Параллельно сливает отсортированные подмассивы на GPU\n",
        "// 4) Замеряет время выполнения и выводит в миллисекундах\n",
        "//\n",
        "// Сборка (Linux / Colab):\n",
        "// nvcc lab4_cuda_merge.cu -O2 -o lab4_cuda_merge\n",
        "// ./lab4_cuda_merge\n",
        "//\n",
        "// Сборка (Windows):\n",
        "// nvcc lab4_cuda_merge.cu -O2 -o lab4_cuda_merge.exe\n",
        "// lab4_cuda_merge.exe\n",
        "//\n",
        "\n",
        "#include <iostream>\n",
        "#include <cstdlib>       // Для rand()\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Размер блока CUDA\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// ===================== Сортировка выбором внутри блока =====================\n",
        "// Простая функция сортировки подмассива (для демонстрации принципа)\n",
        "__device__ void selectionSortDevice(int* data, int size) {\n",
        "    for (int i = 0; i < size-1; i++) {\n",
        "        int minIdx = i;\n",
        "        for (int j = i+1; j < size; j++) {\n",
        "            if (data[j] < data[minIdx]) minIdx = j;\n",
        "        }\n",
        "        int tmp = data[i];\n",
        "        data[i] = data[minIdx];\n",
        "        data[minIdx] = tmp;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===================== Сортировка блоков =====================\n",
        "// Каждый блок GPU сортирует свой подмассив\n",
        "__global__ void sortBlocks(int* d_data, int subArraySize, int N) {\n",
        "    int blockStart = blockIdx.x * subArraySize;\n",
        "    int blockEnd = blockStart + subArraySize;\n",
        "    if (blockEnd > N) blockEnd = N;\n",
        "\n",
        "    selectionSortDevice(d_data + blockStart, blockEnd - blockStart);\n",
        "}\n",
        "\n",
        "// ===================== Параллельное слияние двух подмассивов =====================\n",
        "__global__ void mergeArrays(int* d_data, int* d_temp, int width, int N) {\n",
        "    int idx = blockIdx.x * 2 * width; // индекс первого элемента пары подмассивов\n",
        "\n",
        "    int left = idx;\n",
        "    int mid = min(left + width, N);\n",
        "    int right = min(left + 2*width, N);\n",
        "\n",
        "    int i = left, j = mid, k = left;\n",
        "    while (i < mid && j < right) {\n",
        "        if (d_data[i] <= d_data[j])\n",
        "            d_temp[k++] = d_data[i++];\n",
        "        else\n",
        "            d_temp[k++] = d_data[j++];\n",
        "    }\n",
        "    while (i < mid) d_temp[k++] = d_data[i++];\n",
        "    while (j < right) d_temp[k++] = d_data[j++];\n",
        "}\n",
        "\n",
        "// ===================== Главная функция =====================\n",
        "int main() {\n",
        "    // Размеры массивов\n",
        "    int sizes[] = {10000, 100000};\n",
        "\n",
        "    for (int s = 0; s < 2; s++) {\n",
        "        int N = sizes[s];\n",
        "\n",
        "        // ===================== Создаём массив на хосте =====================\n",
        "        int* h_data = new int[N];\n",
        "        for (int i = 0; i < N; i++)\n",
        "            h_data[i] = rand() % 100000;  // случайные числа от 0 до 99999\n",
        "\n",
        "        // ===================== Выделяем память на GPU =====================\n",
        "        int* d_data;\n",
        "        int* d_temp;\n",
        "        cudaMalloc(&d_data, N * sizeof(int));\n",
        "        cudaMalloc(&d_temp, N * sizeof(int));\n",
        "\n",
        "        // Копируем данные на GPU\n",
        "        cudaMemcpy(d_data, h_data, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // ===================== Сортировка подмассивов блоками =====================\n",
        "        int subArraySize = 1024; // размер подмассива для одного блока\n",
        "        int numBlocks = (N + subArraySize - 1) / subArraySize;\n",
        "\n",
        "        // Создаём события CUDA для точного замера времени\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        // Сортируем каждый блок\n",
        "        sortBlocks<<<numBlocks, 1>>>(d_data, subArraySize, N);\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        // ===================== Параллельное слияние =====================\n",
        "        // После сортировки подмассивов сливаем их попарно\n",
        "        for (int width = subArraySize; width < N; width *= 2) {\n",
        "            int numMergeBlocks = (N + 2*width - 1) / (2*width);\n",
        "            mergeArrays<<<numMergeBlocks, 1>>>(d_data, d_temp, width, N);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            // Меняем массивы местами\n",
        "            int* tmp = d_data;\n",
        "            d_data = d_temp;\n",
        "            d_temp = tmp;\n",
        "        }\n",
        "\n",
        "        // ===================== Замер времени =====================\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        float milliseconds = 0;\n",
        "        cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "        std::cout << \"Array size \" << N << \" - GPU Merge Sort time: \"\n",
        "                  << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "        // ===================== Освобождаем память =====================\n",
        "        cudaFree(d_data);\n",
        "        cudaFree(d_temp);\n",
        "        delete[] h_data;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "0E-2kQqez4W2",
        "outputId": "ca169a67-3151-408b-8976-684712da8834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing lab4_cuda_merge.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lab2_4.cu\n",
        "// lab2_4.cu\n",
        "// Параллельная сортировка слиянием на GPU с использованием CUDA\n",
        "//\n",
        "// Программа:\n",
        "// 1) Создаёт массивы размером 10 000 и 100 000 элементов\n",
        "// 2) Разделяет массив на подмассивы, каждый из которых сортирует отдельный блок\n",
        "// 3) Параллельно сливает отсортированные подмассивы на GPU\n",
        "// 4) Замеряет время выполнения и выводит в миллисекундах\n",
        "//\n",
        "// Сборка (Windows):\n",
        "// nvcc lab2_4.cu -O2 -o lab2_4.exe\n",
        "// lab2_4.exe\n",
        "//\n",
        "\n",
        "#include <iostream>         // для std::cout\n",
        "#include <cstdlib>          // для rand()\n",
        "#include <cuda_runtime.h>   // CUDA runtime\n",
        "#include <algorithm>        // для min() в некоторых случаях\n",
        "\n",
        "// Размер блока CUDA\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "// ===================== Функция сортировки выбором =====================\n",
        "// __device__ означает, что функция выполняется на GPU и может вызываться только с ядра (__global__) или другой __device__ функции\n",
        "__device__ void selectionSortDevice(int* data, int size) {\n",
        "    // Простейший алгоритм сортировки для небольшого подмассива\n",
        "    for (int i = 0; i < size-1; i++) {\n",
        "        int minIdx = i;\n",
        "        for (int j = i+1; j < size; j++) {\n",
        "            if (data[j] < data[minIdx])\n",
        "                minIdx = j;\n",
        "        }\n",
        "        // Меняем местами элементы\n",
        "        int tmp = data[i];\n",
        "        data[i] = data[minIdx];\n",
        "        data[minIdx] = tmp;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===================== Ядро сортировки блоков =====================\n",
        "// Каждый блок GPU сортирует один подмассив из subArraySize элементов\n",
        "__global__ void sortBlocks(int* d_data, int subArraySize, int N) {\n",
        "    int blockStart = blockIdx.x * subArraySize;          // индекс начала подмассива для блока\n",
        "    int blockEnd = blockStart + subArraySize;           // индекс конца подмассива\n",
        "    if (blockEnd > N) blockEnd = N;                     // проверка, чтобы не выйти за пределы массива\n",
        "\n",
        "    // Сортировка подмассива выбором\n",
        "    selectionSortDevice(d_data + blockStart, blockEnd - blockStart);\n",
        "}\n",
        "\n",
        "// ===================== Ядро параллельного слияния =====================\n",
        "// Каждый блок сливает два соседних подмассива\n",
        "__global__ void mergeArrays(int* d_data, int* d_temp, int width, int N) {\n",
        "    int idx = blockIdx.x * 2 * width;                   // индекс первого элемента пары подмассивов\n",
        "\n",
        "    int left = idx;\n",
        "    int mid = (left + width < N) ? left + width : N;   // середина подмассива\n",
        "    int right = (left + 2*width < N) ? left + 2*width : N; // конец второго подмассива\n",
        "\n",
        "    int i = left, j = mid, k = left;                   // индексы для левого, правого и временного массива\n",
        "    while (i < mid && j < right) {\n",
        "        if (d_data[i] <= d_data[j])\n",
        "            d_temp[k++] = d_data[i++];\n",
        "        else\n",
        "            d_temp[k++] = d_data[j++];\n",
        "    }\n",
        "\n",
        "    // Копируем оставшиеся элементы левого подмассива\n",
        "    while (i < mid) d_temp[k++] = d_data[i++];\n",
        "    // Копируем оставшиеся элементы правого подмассива\n",
        "    while (j < right) d_temp[k++] = d_data[j++];\n",
        "}\n",
        "\n",
        "// ===================== Макрос для проверки ошибок CUDA =====================\n",
        "#define CUDA_CHECK(err) \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        std::cerr << \"CUDA Error: \" << cudaGetErrorString(err) << std::endl; \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    }\n",
        "\n",
        "// ===================== Главная функция =====================\n",
        "int main() {\n",
        "    // Определяем размеры массивов, которые будем сортировать\n",
        "    int sizes[] = {10000, 100000};\n",
        "\n",
        "    for (int s = 0; s < 2; s++) {\n",
        "        int N = sizes[s];\n",
        "\n",
        "        // ===================== Создаём массив на хосте =====================\n",
        "        int* h_data = new int[N];\n",
        "        for (int i = 0; i < N; i++)\n",
        "            h_data[i] = rand() % 100000;  // случайные числа от 0 до 99999\n",
        "\n",
        "        // ===================== Выделяем память на GPU =====================\n",
        "        int *d_data, *d_temp;\n",
        "        CUDA_CHECK(cudaMalloc(&d_data, N * sizeof(int))); // основной массив на GPU\n",
        "        CUDA_CHECK(cudaMalloc(&d_temp, N * sizeof(int))); // временный массив для слияния\n",
        "\n",
        "        // Копируем данные с CPU на GPU\n",
        "        CUDA_CHECK(cudaMemcpy(d_data, h_data, N * sizeof(int), cudaMemcpyHostToDevice));\n",
        "\n",
        "        // Размер подмассива для одного блока\n",
        "        int subArraySize = 1024;\n",
        "        int numBlocks = (N + subArraySize - 1) / subArraySize; // количество блоков\n",
        "\n",
        "        // ===================== Создаём события CUDA для измерения времени =====================\n",
        "        cudaEvent_t start, stop;\n",
        "        CUDA_CHECK(cudaEventCreate(&start));\n",
        "        CUDA_CHECK(cudaEventCreate(&stop));\n",
        "        CUDA_CHECK(cudaEventRecord(start));\n",
        "\n",
        "        // ===================== Сортировка каждого блока =====================\n",
        "        sortBlocks<<<numBlocks, 1>>>(d_data, subArraySize, N);\n",
        "        CUDA_CHECK(cudaDeviceSynchronize()); // ожидание завершения сортировки\n",
        "\n",
        "        // ===================== Параллельное слияние подмассивов =====================\n",
        "        for (int width = subArraySize; width < N; width *= 2) {\n",
        "            int numMergeBlocks = (N + 2*width - 1) / (2*width); // количество блоков для слияния\n",
        "            mergeArrays<<<numMergeBlocks, 1>>>(d_data, d_temp, width, N);\n",
        "            CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "            // Меняем массивы местами, чтобы следующий шаг слияния работал с новым массивом\n",
        "            int* tmp = d_data;\n",
        "            d_data = d_temp;\n",
        "            d_temp = tmp;\n",
        "        }\n",
        "\n",
        "        // ===================== Замер времени =====================\n",
        "        CUDA_CHECK(cudaEventRecord(stop));\n",
        "        CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "        float milliseconds = 0;\n",
        "        CUDA_CHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "\n",
        "        // Выводим время сортировки в миллисекундах\n",
        "        std::cout << \"Array size \" << N << \" - GPU Merge Sort time: \"\n",
        "                  << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "        // ===================== Освобождение памяти =====================\n",
        "        CUDA_CHECK(cudaFree(d_data));\n",
        "        CUDA_CHECK(cudaFree(d_temp));\n",
        "        delete[] h_data;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N0GX5ICQ0-N4",
        "outputId": "8da6237f-e8fc-43ef-dd36-50e4ae106c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lab2_4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc lab2_4.cu -O2 -o lab2_4\n"
      ],
      "metadata": {
        "id": "rLT6O0Xo2hTn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./lab2_4\n"
      ],
      "metadata": {
        "id": "eQWyquPB1sSv",
        "outputId": "168d5223-4d83-4bb7-a448-e2604a843970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array size 10000 - GPU Merge Sort time: 7.21062 ms\n",
            "Array size 100000 - GPU Merge Sort time: 0.01376 ms\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}