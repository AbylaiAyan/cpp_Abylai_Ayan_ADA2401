# Практическая работа №5  
## Реализация параллельных структур данных на GPU (CUDA)

### Цель работы
Изучить принципы реализации параллельных структур данных на GPU с использованием технологии CUDA, а также исследовать корректность и производительность их работы при параллельном доступе множества потоков.

---

## Используемые технологии
- CUDA (NVIDIA)
- C++
- Google Colab с поддержкой GPU
- Компилятор `nvcc`

---

## Структура проекта

- `stack_cuda.cu` — реализация параллельного стека (LIFO) на GPU  
- `queue_vs_stack.cu` — реализация параллельного стека и очереди (FIFO) и сравнение их производительности  
- `part1` — скомпилированная программа для проверки корректности стека  
- `part2` — скомпилированная программа для сравнения времени выполнения  

---

## Часть 1. Параллельный стек

В первой части реализован параллельный стек фиксированной ёмкости.  
Несколько CUDA-потоков одновременно выполняют операции добавления (`push`) и извлечения (`pop`) элементов.

Для обеспечения корректного доступа используется механизм атомарных операций CUDA (`atomicAdd`, `atomicSub`).

### Результат выполнения
Количество успешных операций pop: 256

Максимально возможное значение: 1024


Данный результат подтверждает корректность работы стека: количество успешных операций не превышает его максимальную ёмкость.


**Скриншот :**  
![part 1](part1output.png)

---

---

## Часть 2. Параллельный стек и очередь

Во второй части реализованы:
- параллельный стек (LIFO)
- параллельная очередь (FIFO)

Также проведено измерение времени выполнения операций добавления и удаления элементов с использованием CUDA Events.

### Результат выполнения
Время выполнения стека: 11.2188 мс

Время выполнения очереди: 0.002528 мс


Результаты показывают различия в производительности структур данных при параллельном доступе.

**Скриншот :**  
![part 2](part2output.png)


---
---

## Выводы
- Параллельные структуры данных могут быть эффективно реализованы на GPU с использованием CUDA.
- Атомарные операции позволяют избежать конфликтов при одновременном доступе потоков.
- Очередь и стек имеют разные характеристики производительности из-за различий в логике синхронизации.
- GPU позволяет эффективно обрабатывать большое количество параллельных операций.

---

## Автор
Практическая работа выполнена в рамках изучения параллельного программирования и CUDA.



Результаты демонстрируют различия в производительности структур данных при параллельном доступе потоков.

---

## Выводы

- Параллельные структуры данных могут эффективно реализовываться на GPU с использованием CUDA.
- Атомарные операции позволяют обеспечить корректную работу при одновременном доступе множества потоков.
- Очередь и стек имеют различные характеристики производительности из-за различий в логике синхронизации.
- Использование GPU позволяет обрабатывать большое количество операций параллельно.

---

## Контрольные вопросы

### 1. В чём отличие стека и очереди?

Стек работает по принципу **LIFO** (последним пришёл — первым вышел), а очередь — по принципу **FIFO** (первым пришёл — первым вышел).  
В стеке операции добавления и удаления выполняются с одного конца, а в очереди добавление происходит в конец, а удаление — из начала.

---

### 2. Какие проблемы возникают при параллельном доступе к данным?

При параллельном доступе могут возникать:
- состояния гонки (race conditions)
- потеря или повреждение данных
- некорректные результаты вычислений
- одновременная запись в одну и ту же область памяти

---

### 3. Как атомарные операции помогают избежать конфликтов в параллельных структурах данных?

Атомарные операции гарантируют, что операция над переменной будет выполнена полностью и неделимо.  
Это предотвращает одновременное изменение данных несколькими потоками и обеспечивает корректную синхронизацию.

---

### 4. Какие типы памяти CUDA используются для хранения данных?

В CUDA используются следующие типы памяти:
- глобальная память
- разделяемая память
- локальная память
- регистры
- константная память
- текстурная память  

В данной работе структуры данных размещаются в глобальной памяти GPU.

---

### 5. Как синхронизация потоков влияет на производительность?

Синхронизация повышает корректность выполнения программ, однако может снижать производительность из-за ожидания потоков и дополнительных накладных расходов, связанных с атомарными операциями и барьерами синхронизации.

---

### 6. Почему разделяемая память важна для оптимизации работы параллельных структур данных?

Разделяемая память обладает высокой скоростью доступа и доступна всем потокам одного блока.  
Её использование снижает количество обращений к глобальной памяти и позволяет существенно повысить производительность параллельных алгоритмов.

---

## Итог

Все задачи практической работы выполнены. Реализованы параллельные структуры данных, проверена их корректность и проведено сравнение производительности.
