{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Запись CUDA-кода в файл stack_cuda.cu\n",
        "%%writefile part1.cu\n",
        "\n",
        "// Подключение CUDA Runtime (память, ядра, атомарные операции)\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Подключение стандартного вывода\n",
        "#include <iostream>\n",
        "\n",
        "// Максимальная вместимость стека\n",
        "#define STACK_CAPACITY 1024\n",
        "\n",
        "// Количество потоков CUDA\n",
        "#define THREADS 256\n",
        "\n",
        "//\n",
        "// Структура параллельного стека\n",
        "//\n",
        "\n",
        "// Стек, размещённый в глобальной памяти GPU\n",
        "struct Stack {\n",
        "    int data[STACK_CAPACITY]; // Массив элементов стека\n",
        "    int top;                  // Индекс вершины стека\n",
        "};\n",
        "\n",
        "//\n",
        "// Добавление элемента в стек\n",
        "//\n",
        "\n",
        "// Устройство-функция для операции push\n",
        "__device__ bool stack_push(Stack* stack, int value) {\n",
        "\n",
        "    // Атомарно увеличиваем указатель вершины\n",
        "    int position = atomicAdd(&stack->top, 1);\n",
        "\n",
        "    // Проверка на переполнение стека\n",
        "    if (position >= STACK_CAPACITY) {\n",
        "        // Откат изменения, если стек переполнен\n",
        "        atomicSub(&stack->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Записываем значение в стек\n",
        "    stack->data[position] = value;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//\n",
        "// Удаление элемента из стека\n",
        "//\n",
        "\n",
        "// Устройство-функция для операции pop\n",
        "__device__ bool stack_pop(Stack* stack, int* result) {\n",
        "\n",
        "    // Атомарно уменьшаем вершину стека\n",
        "    int position = atomicSub(&stack->top, 1) - 1;\n",
        "\n",
        "    // Проверка на пустой стек\n",
        "    if (position < 0) {\n",
        "        // Возвращаем указатель вершины назад\n",
        "        atomicAdd(&stack->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Считываем значение\n",
        "    *result = stack->data[position];\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//\n",
        "// Ядро: параллельное добавление\n",
        "//\n",
        "\n",
        "// Каждый поток кладёт значение в стек\n",
        "__global__ void push_kernel(Stack* stack) {\n",
        "\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    stack_push(stack, tid);\n",
        "}\n",
        "\n",
        "//\n",
        "// Ядро: параллельное удаление\n",
        "//\n",
        "\n",
        "// Каждый поток пытается извлечь значение из стека\n",
        "__global__ void pop_kernel(Stack* stack, int* output) {\n",
        "\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int value;\n",
        "\n",
        "    if (stack_pop(stack, &value))\n",
        "        output[tid] = value;\n",
        "    else\n",
        "        output[tid] = -1;\n",
        "}\n",
        "\n",
        "//\n",
        "// Главная функция\n",
        "//\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Указатели на данные в памяти GPU\n",
        "    Stack* d_stack;\n",
        "    int* d_output;\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));\n",
        "\n",
        "    // Создание и инициализация стека на CPU\n",
        "    Stack h_stack;\n",
        "    h_stack.top = 0;\n",
        "\n",
        "    // Копирование стека на GPU\n",
        "    cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Запуск ядра добавления элементов\n",
        "    push_kernel<<<1, THREADS>>>(d_stack);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Запуск ядра извлечения элементов\n",
        "    pop_kernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Массив для хранения результатов на CPU\n",
        "    int h_output[THREADS];\n",
        "\n",
        "    // Копирование результатов с GPU\n",
        "    cudaMemcpy(h_output, d_output, THREADS * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Подсчёт успешных операций pop\n",
        "    int successful = 0;\n",
        "    for (int i = 0; i < THREADS; i++) {\n",
        "        if (h_output[i] != -1)\n",
        "            successful++;\n",
        "    }\n",
        "\n",
        "    // Вывод результатов\n",
        "    std::cout << \"Количество успешных операций pop: \" << successful << std::endl;\n",
        "    std::cout << \"Максимально возможное значение: \" << STACK_CAPACITY << std::endl;\n",
        "\n",
        "    // Освобождение памяти GPU\n",
        "    cudaFree(d_stack);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "3o97aBRvazQ0",
        "outputId": "5ec959dc-08ba-4984-f889-465eef9168d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting part1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc part1.cu -o part1"
      ],
      "metadata": {
        "id": "Nj6DjJEja8bT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!./part1"
      ],
      "metadata": {
        "id": "iqUlFa7Ja9eq",
        "outputId": "b6aef45e-51e0-4d10-9e45-3791467d5d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество успешных операций pop: 256\n",
            "Максимально возможное значение: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запись CUDA-кода в файл queue_vs_stack.cu\n",
        "%%writefile part2.cu\n",
        "\n",
        "// Подключение CUDA Runtime (память, ядра, атомарные операции)\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Подключение стандартного вывода\n",
        "#include <iostream>\n",
        "\n",
        "// Максимальная вместимость стека и очереди\n",
        "#define CAPACITY 1024\n",
        "\n",
        "// Количество CUDA-потоков\n",
        "#define THREADS 256\n",
        "\n",
        "//\n",
        "// Структура параллельного стека\n",
        "//\n",
        "\n",
        "// Стек (LIFO), размещённый в глобальной памяти GPU\n",
        "struct Stack {\n",
        "    int data[CAPACITY]; // Массив для хранения элементов\n",
        "    int top;            // Указатель вершины стека\n",
        "};\n",
        "\n",
        "//\n",
        "// Структура параллельной очереди\n",
        "//\n",
        "\n",
        "// Очередь (FIFO), реализованная как кольцевой буфер\n",
        "struct Queue {\n",
        "    int data[CAPACITY]; // Буфер для элементов\n",
        "    int head;           // Индекс чтения\n",
        "    int tail;           // Индекс записи\n",
        "    int size;           // Текущее количество элементов\n",
        "};\n",
        "\n",
        "//\n",
        "// Операция push для стека\n",
        "//\n",
        "\n",
        "// Устройство-функция добавления элемента в стек\n",
        "__device__ bool stack_push(Stack* stack, int value) {\n",
        "\n",
        "    // Атомарно увеличиваем указатель вершины\n",
        "    int pos = atomicAdd(&stack->top, 1);\n",
        "\n",
        "    // Проверка переполнения\n",
        "    if (pos >= CAPACITY) {\n",
        "        atomicSub(&stack->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Запись значения\n",
        "    stack->data[pos] = value;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//\n",
        "// Операция pop для стека\n",
        "//\n",
        "\n",
        "// Устройство-функция извлечения элемента из стека\n",
        "__device__ bool stack_pop(Stack* stack, int* result) {\n",
        "\n",
        "    // Атомарно уменьшаем указатель вершины\n",
        "    int pos = atomicSub(&stack->top, 1) - 1;\n",
        "\n",
        "    // Проверка на пустой стек\n",
        "    if (pos < 0) {\n",
        "        atomicAdd(&stack->top, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Считывание значения\n",
        "    *result = stack->data[pos];\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//\n",
        "// Операция enqueue для очереди\n",
        "//\n",
        "\n",
        "// Устройство-функция добавления элемента в очередь\n",
        "__device__ bool queue_enqueue(Queue* queue, int value) {\n",
        "\n",
        "    // Резервируем позицию для записи\n",
        "    int pos = atomicAdd(&queue->tail, 1);\n",
        "\n",
        "    // Увеличиваем размер очереди и проверяем переполнение\n",
        "    if (atomicAdd(&queue->size, 1) >= CAPACITY) {\n",
        "        atomicSub(&queue->tail, 1);\n",
        "        atomicSub(&queue->size, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Запись элемента (кольцевой буфер)\n",
        "    queue->data[pos % CAPACITY] = value;\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//\n",
        "// Операция dequeue для очереди\n",
        "//\n",
        "\n",
        "// Устройство-функция извлечения элемента из очереди\n",
        "__device__ bool queue_dequeue(Queue* queue, int* result) {\n",
        "\n",
        "    // Уменьшаем размер очереди и проверяем пустоту\n",
        "    if (atomicSub(&queue->size, 1) <= 0) {\n",
        "        atomicAdd(&queue->size, 1);\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    // Резервируем позицию для чтения\n",
        "    int pos = atomicAdd(&queue->head, 1);\n",
        "\n",
        "    // Считывание элемента\n",
        "    *result = queue->data[pos % CAPACITY];\n",
        "    return true;\n",
        "}\n",
        "\n",
        "//\n",
        "// CUDA-ядра для стека\n",
        "//\n",
        "\n",
        "// Параллельное добавление в стек\n",
        "__global__ void stack_push_kernel(Stack* stack) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    stack_push(stack, tid);\n",
        "}\n",
        "\n",
        "// Параллельное извлечение из стека\n",
        "__global__ void stack_pop_kernel(Stack* stack, int* output) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int value;\n",
        "\n",
        "    if (stack_pop(stack, &value))\n",
        "        output[tid] = value;\n",
        "    else\n",
        "        output[tid] = -1;\n",
        "}\n",
        "\n",
        "//\n",
        "// CUDA-ядра для очереди\n",
        "//\n",
        "\n",
        "// Параллельное добавление в очередь\n",
        "__global__ void queue_enqueue_kernel(Queue* queue) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    queue_enqueue(queue, tid);\n",
        "}\n",
        "\n",
        "// Параллельное извлечение из очереди\n",
        "__global__ void queue_dequeue_kernel(Queue* queue, int* output) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int value;\n",
        "\n",
        "    if (queue_dequeue(queue, &value))\n",
        "        output[tid] = value;\n",
        "    else\n",
        "        output[tid] = -1;\n",
        "}\n",
        "\n",
        "//\n",
        "// Главная функция\n",
        "//\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // Указатели на данные в памяти GPU\n",
        "    Stack* d_stack;\n",
        "    Queue* d_queue;\n",
        "    int* d_output;\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "    cudaMalloc(&d_stack, sizeof(Stack));\n",
        "    cudaMalloc(&d_queue, sizeof(Queue));\n",
        "    cudaMalloc(&d_output, THREADS * sizeof(int));\n",
        "\n",
        "    // Инициализация стека на CPU\n",
        "    Stack h_stack;\n",
        "    h_stack.top = 0;\n",
        "\n",
        "    // Инициализация очереди на CPU\n",
        "    Queue h_queue;\n",
        "    h_queue.head = 0;\n",
        "    h_queue.tail = 0;\n",
        "    h_queue.size = 0;\n",
        "\n",
        "    // Копирование данных на GPU\n",
        "    cudaMemcpy(d_stack, &h_stack, sizeof(Stack), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_queue, &h_queue, sizeof(Queue), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // События CUDA для измерения времени\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    //\n",
        "    // Измерение времени стека\n",
        "    //\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    stack_push_kernel<<<1, THREADS>>>(d_stack);\n",
        "    stack_pop_kernel<<<1, THREADS>>>(d_stack, d_output);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float stack_time;\n",
        "    cudaEventElapsedTime(&stack_time, start, stop);\n",
        "\n",
        "    //\n",
        "    // Измерение времени очереди\n",
        "    //\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    queue_enqueue_kernel<<<1, THREADS>>>(d_queue);\n",
        "    queue_dequeue_kernel<<<1, THREADS>>>(d_queue, d_output);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float queue_time;\n",
        "    cudaEventElapsedTime(&queue_time, start, stop);\n",
        "\n",
        "    //\n",
        "    // Вывод результатов\n",
        "    //\n",
        "\n",
        "    std::cout << \"Время выполнения стека: \" << stack_time << \" мс\" << std::endl;\n",
        "    std::cout << \"Время выполнения очереди: \" << queue_time << \" мс\" << std::endl;\n",
        "\n",
        "    // Освобождение памяти GPU\n",
        "    cudaFree(d_stack);\n",
        "    cudaFree(d_queue);\n",
        "    cudaFree(d_output);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "hNDvQ35kbA8C",
        "outputId": "8bfb0f0e-c644-47d5-c61a-1c29b5eaea23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing part2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!nvcc part2.cu -o part2"
      ],
      "metadata": {
        "id": "mKBwUS6WbCVq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./part2"
      ],
      "metadata": {
        "id": "Cac8grcybDfM",
        "outputId": "a4dd3ed1-131c-4504-b5f2-96154c12d4e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения стека: 11.2188 мс\n",
            "Время выполнения очереди: 0.002528 мс\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}