{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUwy_33YQqTV",
        "outputId": "bb0e4620-6adc-434c-f01b-bc5db292095a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 18 13:30:45 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile task3.cu\n",
        "#include <cuda_runtime.h>   // библиотека для работы с CUDA\n",
        "#include <iostream>         // ввод / вывод\n",
        "#include <chrono>           // замер времени\n",
        "\n",
        "// количество элементов в массиве\n",
        "#define N 1000000\n",
        "\n",
        "// размер блока потоков\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "//\n",
        "// CUDA-ЯДРО с КОАЛЕСЦИРОВАННЫМ доступом к памяти\n",
        "//\n",
        "// В этом ядре каждый поток работает со \"своим\" элементом массива\n",
        "// Потоки с соседними индексами обращаются к соседним ячейкам памяти\n",
        "// Это самый эффективный вариант работы с глобальной памятью\n",
        "__global__ void coalesced_access(float* data) {\n",
        "\n",
        "    // вычисляем глобальный индекс элемента\n",
        "    // blockIdx.x   — номер блока\n",
        "    // blockDim.x   — количество потоков в блоке\n",
        "    // threadIdx.x  — номер потока внутри блока\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // проверяем, что не вышли за границы массива\n",
        "    if (idx < N) {\n",
        "        // каждый поток читает и записывает\n",
        "        // соседний элемент массива\n",
        "        // такой доступ является коалесцированным\n",
        "        data[idx] = data[idx] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "//\n",
        "// CUDA-ЯДРО с НЕКОАЛЕСЦИРОВАННЫМ доступом к памяти\n",
        "//\n",
        "// Здесь потоки обращаются к памяти \"скачками\"\n",
        "// Это приводит к большому количеству отдельных обращений\n",
        "// к глобальной памяти и снижает производительность\n",
        "__global__ void non_coalesced_access(float* data) {\n",
        "\n",
        "    // вычисляем глобальный индекс потока\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // намеренно делаем плохой шаблон доступа:\n",
        "    // каждый поток обращается к элементу через шаг 2\n",
        "    int access_index = idx * 2;\n",
        "\n",
        "    // проверяем выход за границы массива\n",
        "    if (access_index < N) {\n",
        "        // такой доступ считается некоалесцированным\n",
        "        data[access_index] = data[access_index] * 2.0f;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    //\n",
        "    // Выделение памяти на CPU\n",
        "    //\n",
        "    float* h_data = new float[N];\n",
        "\n",
        "    // указатель на память на GPU\n",
        "    float* d_data;\n",
        "\n",
        "    //\n",
        "    // Инициализация массива на CPU\n",
        "    //\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_data[i] = 1.0f;\n",
        "    }\n",
        "\n",
        "    //\n",
        "    // Выделение памяти на CPU\n",
        "    //\n",
        "    cudaMalloc(&d_data, N * sizeof(float));\n",
        "\n",
        "    //\n",
        "    // Копирование данных с CPU на GPU\n",
        "    //\n",
        "    cudaMemcpy(d_data, h_data, N * sizeof(float),\n",
        "               cudaMemcpyHostToDevice);\n",
        "\n",
        "    //\n",
        "    // настройка сетки и блоков\n",
        "    //\n",
        "    dim3 block(BLOCK_SIZE);                     // размер блока\n",
        "    dim3 grid((N + BLOCK_SIZE - 1) / BLOCK_SIZE); // количество блоков\n",
        "\n",
        "    //\n",
        "    // Замер времени: КОАЛЕСЦИРОВАННЫЙ доступ\n",
        "    //\n",
        "    auto start_coal = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // запуск CUDA-ядра\n",
        "    coalesced_access<<<grid, block>>>(d_data);\n",
        "\n",
        "    // ждём завершения всех потоков\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto end_coal = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> time_coal = end_coal - start_coal;\n",
        "\n",
        "    //\n",
        "    // замер времени: НЕКОАЛЕСЦИРОВАННЫЙ лоступ\n",
        "    //\n",
        "    auto start_non = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // запуск второго CUDA-ядра\n",
        "    non_coalesced_access<<<grid, block>>>(d_data);\n",
        "\n",
        "    // синхронизация устройства\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto end_non = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double> time_non = end_non - start_non;\n",
        "\n",
        "\n",
        "    std::cout << \"Коалесцированный доступ:   \"\n",
        "              << time_coal.count() << \" секунд\\n\";\n",
        "\n",
        "    std::cout << \"Некоалесцированный доступ: \"\n",
        "              << time_non.count() << \" секунд\\n\";\n",
        "\n",
        "    cudaFree(d_data);     // память GPU\n",
        "    delete[] h_data;      // память CPU\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "KTimWP6OTRRK",
        "outputId": "56775b58-659e-4ae7-9489-58bf3b99d1f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting task3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc task3.cu -o task3\n"
      ],
      "metadata": {
        "id": "VokKABoXUTB5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./task3\n"
      ],
      "metadata": {
        "id": "yhJASuUDUUdZ",
        "outputId": "b7eba352-2778-4cb1-87a8-804f05d16ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Коалесцированный доступ:   0.00752707 секунд\n",
            "Некоалесцированный доступ: 2.848e-06 секунд\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}