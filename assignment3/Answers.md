# Ответы на контрольные вопросы Assignment 3

## 1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

Основные типы памяти в CUDA:

- **Регистры (Registers)**  
  - Хранят данные каждого потока.  
  - Очень быстрые (самый быстрый доступ), но ограничены по объёму.  

- **Shared memory (разделяемая память)**  
  - Общая память для всех потоков блока.  
  - Быстрая (намного быстрее глобальной), но ограничена по размеру (~48 КБ на блок для современных GPU).  

- **Global memory (глобальная память)**  
  - Общая для всех потоков всех блоков.  
  - Большая, но медленная (200–400 раз медленнее регистров).  

- **Local memory (локальная память)**  
  - На самом деле часть глобальной памяти, используется для хранения данных, которые не помещаются в регистры.  
  - Медленная, так как находится в глобальной памяти.  

- **Texture / Constant memory**  
  - Оптимизированы для специальных паттернов доступа.  
  - Constant memory быстры при чтении одинаковых значений всеми потоками.  

**Вывод:** скорость доступа зависит от близости памяти к вычислительным блокам и от её назначения.

---

## 2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

- Когда **одни и те же данные используются несколькими потоками одного блока**.  
- Пример: умножение матриц, свертки, поэлементная обработка с повторным использованием.  
- Shared memory позволяет **сократить количество медленных обращений к глобальной памяти**, ускоряя выполнение программы.  

---

## 3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

- Если потоки обращаются к **соседним элементам массива** → доступ **коалесцированный** → GPU объединяет запросы → высокая пропускная способность → быстро.  
- Если потоки обращаются к элементам случайно или с большими прыжками → **некоалесцированный доступ** → много отдельных запросов к памяти → медленно.  
- Вывод: **правильный шаблон доступа к памяти критичен для производительности**.

---

## 4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

- Потому что **скорость выполнения сильно зависит от шаблона доступа к памяти** (коалесцированный vs некоалесцированный).  
- Использование **shared memory** или **регистров** также может сильно ускорить программу.  
- Даже один и тот же алгоритм, но с разной организацией данных в памяти, будет работать с разной эффективностью.

---

## 5. Как размер блока потоков влияет на производительность CUDA-ядра?

- Размер блока определяет, **сколько потоков одновременно работает на одном мультипроцессоре**.  
- Слишком маленький блок → GPU недозагружен → низкая производительность.  
- Слишком большой блок → может превышать доступную shared memory или регистры → часть потоков не активна → производительность падает.  
- Оптимальный размер блока обеспечивает **максимальную загрузку GPU** и минимальное время выполнения.

---

## 6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

- **Варп (Warp)** — группа из 32 потоков (на современных NVIDIA GPU), которые выполняются одновременно.  
- Важно, потому что:  
  - Все потоки варпа выполняются синхронно.  
  - Если потоки варпа идут разными ветками (divergence), GPU вынужден выполнять их поочередно → падение производительности.  
- При проектировании CUDA-программ важно **минимизировать разветвления внутри варпа**.

---

## 7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

- Количество потоков в блоке (для оптимальной загрузки мультипроцессоров).  
- Размер разделяемой памяти на блок.  
- Количество регистров на поток.  
- Общее количество потоков для покрытия всех элементов данных.  
- Баланс между количеством блоков и размером блоков для эффективного использования всех вычислительных ресурсов GPU.  

---

## 8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

- **Доступ к памяти часто является узким местом (bottleneck) на GPU**.  
- Алгоритм может быть идеальным, но медленным из-за медленной глобальной памяти.  
- Оптимизация памяти (shared memory, коалесцированный доступ, регистры) обычно даёт **больший прирост производительности**, чем изменение самого алгоритма.  
- Поэтому анализ работы с памятью — **первый шаг к эффективной CUDA-программе**.
